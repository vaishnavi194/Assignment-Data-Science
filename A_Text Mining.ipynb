{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vaish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vaish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: textblob in c:\\users\\vaish\\anaconda3sfw\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied, skipping upgrade: nltk>=3.1; python_version >= \"3\" in c:\\users\\vaish\\anaconda3sfw\\lib\\site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied, skipping upgrade: regex in c:\\users\\vaish\\anaconda3sfw\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (2020.6.8)\n",
      "Requirement already satisfied, skipping upgrade: joblib in c:\\users\\vaish\\anaconda3sfw\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in c:\\users\\vaish\\anaconda3sfw\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (4.47.0)\n",
      "Requirement already satisfied, skipping upgrade: click in c:\\users\\vaish\\anaconda3sfw\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (7.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Text\n",
       "0           1                             @kunalb11 Im an alien\n",
       "1           2  @ID_AA_Carmack Ray tracing on Cyberpunk with H...\n",
       "2           3                @joerogan @Spotify Great interview!\n",
       "3           4                    @gtera27 Doge is underestimated\n",
       "4           5  @teslacn Congratulations Tesla China for amazi..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Elon_musk.csv',encoding=\"latin-1\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  word_count\n",
       "0                             @kunalb11 Im an alien           4\n",
       "1  @ID_AA_Carmack Ray tracing on Cyberpunk with H...          13\n",
       "2                @joerogan @Spotify Great interview!           4\n",
       "3                    @gtera27 Doge is underestimated           4\n",
       "4  @teslacn Congratulations Tesla China for amazi...          17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['word_count'] = data['Text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "data[['Text','word_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  char_count\n",
       "0                             @kunalb11 Im an alien          22\n",
       "1  @ID_AA_Carmack Ray tracing on Cyberpunk with H...          82\n",
       "2                @joerogan @Spotify Great interview!          35\n",
       "3                    @gtera27 Doge is underestimated          31\n",
       "4  @teslacn Congratulations Tesla China for amazi...         104"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['char_count'] = data['Text'].str.len() ## this also includes spaces\n",
    "data[['Text','char_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>avg_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "      <td>4.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>5.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>5.176471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  avg_word\n",
       "0                             @kunalb11 Im an alien  4.750000\n",
       "1  @ID_AA_Carmack Ray tracing on Cyberpunk with H...  5.384615\n",
       "2                @joerogan @Spotify Great interview!  8.000000\n",
       "3                    @gtera27 Doge is underestimated  7.000000\n",
       "4  @teslacn Congratulations Tesla China for amazi...  5.176471"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avg_word(sentence):\n",
    "  words = sentence.split()\n",
    "  return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "data['avg_word'] = data['Text'].apply(lambda x: avg_word(x))\n",
    "data[['Text','avg_word']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  stopwords\n",
       "0                             @kunalb11 Im an alien          1\n",
       "1  @ID_AA_Carmack Ray tracing on Cyberpunk with H...          4\n",
       "2                @joerogan @Spotify Great interview!          0\n",
       "3                    @gtera27 Doge is underestimated          1\n",
       "4  @teslacn Congratulations Tesla China for amazi...          5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "\n",
    "data['stopwords'] = data['Text'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "data[['Text','stopwords']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>hastags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  hastags\n",
       "0                             @kunalb11 Im an alien        1\n",
       "1  @ID_AA_Carmack Ray tracing on Cyberpunk with H...        1\n",
       "2                @joerogan @Spotify Great interview!        2\n",
       "3                    @gtera27 Doge is underestimated        1\n",
       "4  @teslacn Congratulations Tesla China for amazi...        1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['hastags'] = data['Text'].apply(lambda x: len([x for x in x.split() if x.startswith('@')]))\n",
    "data[['Text','hastags']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>numerics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  numerics\n",
       "0                             @kunalb11 Im an alien         0\n",
       "1  @ID_AA_Carmack Ray tracing on Cyberpunk with H...         0\n",
       "2                @joerogan @Spotify Great interview!         0\n",
       "3                    @gtera27 Doge is underestimated         0\n",
       "4  @teslacn Congratulations Tesla China for amazi...         0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['numerics'] = data['Text'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "data[['Text','numerics']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  upper\n",
       "0                             @kunalb11 Im an alien      0\n",
       "1  @ID_AA_Carmack Ray tracing on Cyberpunk with H...      1\n",
       "2                @joerogan @Spotify Great interview!      0\n",
       "3                    @gtera27 Doge is underestimated      0\n",
       "4  @teslacn Congratulations Tesla China for amazi...      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['upper'] = data['Text'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "data[['Text','upper']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               @kunalb11 im an alien\n",
       "1    @id_aa_carmack ray tracing on cyberpunk with h...\n",
       "2                  @joerogan @spotify great interview!\n",
       "3                      @gtera27 doge is underestimated\n",
       "4    @teslacn congratulations tesla china for amazi...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'] = data['Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "data['Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 kunalb11 im an alien\n",
       "1    id_aa_carmack ray tracing on cyberpunk with hd...\n",
       "2                     joerogan spotify great interview\n",
       "3                       gtera27 doge is underestimated\n",
       "4    teslacn congratulations tesla china for amazin...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'] = data['Text'].str.replace('[^\\w\\s]','')\n",
    "data['Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    kunalb11 im alien\n",
       "1    id_aa_carmack ray tracing cyberpunk hdr nextle...\n",
       "2                     joerogan spotify great interview\n",
       "3                          gtera27 doge underestimated\n",
       "4    teslacn congratulations tesla china amazing ex...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "data['Text'] = data['Text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "data['Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacex            239\n",
       "amp               218\n",
       "tesla             166\n",
       "erdayastronaut    142\n",
       "rt                127\n",
       "ppathole          123\n",
       "flcnhvy           114\n",
       "yes                86\n",
       "great              76\n",
       "teslaownerssv      73\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(data['Text']).split()).value_counts()[:10]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    kunalb11 im alien\n",
       "1    id_aa_carmack ray tracing cyberpunk hdr nextle...\n",
       "2                           joerogan spotify interview\n",
       "3                          gtera27 doge underestimated\n",
       "4    teslacn congratulations china amazing executio...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(freq.index)\n",
    "data['Text'] = data['Text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "data['Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "superheavy            1\n",
       "httpstcokvkrwksvab    1\n",
       "represent             1\n",
       "sh                    1\n",
       "homeespecially        1\n",
       "tracing               1\n",
       "falloutthemed         1\n",
       "coffeemaestro_        1\n",
       "httpstcoalexczij1l    1\n",
       "unlikely              1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(data['Text']).split()).value_counts()[-10:]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    kunalb11 im alien\n",
       "1      id_aa_carmack ray cyberpunk hdr nextlevel tried\n",
       "2                           joerogan spotify interview\n",
       "3                          gtera27 doge underestimated\n",
       "4    teslacn congratulations china amazing executio...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(freq.index)\n",
    "data['Text'] = data['Text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "data['Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    kunalb11 in alien\n",
       "1      id_aa_carmack ray cyberpunk her nextlevel tried\n",
       "2                           joerogan specify interview\n",
       "3                          gtera27 done underestimated\n",
       "4    teslacn congratulations china amazing executio...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'][:5].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    kunalb11 im alien\n",
       "1        id_aa_carmack ray cyberpunk hdr nextlevel tri\n",
       "2                           joerogan spotifi interview\n",
       "3                              gtera27 doge underestim\n",
       "4    teslacn congratul china amaz execut last year ...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()\n",
    "data['Text'][:5].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    kunalb11 im alien\n",
       "1      id_aa_carmack ray cyberpunk hdr nextlevel tried\n",
       "2                           joerogan spotify interview\n",
       "3                          gtera27 doge underestimated\n",
       "4    teslacn congratulation china amazing execution...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'] = data['Text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "data['Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['kunalb11', 'im']), WordList(['im', 'alien'])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(data['Text'][0]).ngrams(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hdr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_aa_carmack</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ray</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cyberpunk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tried</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nextlevel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           words  tf\n",
       "0            hdr   1\n",
       "1  id_aa_carmack   1\n",
       "2            ray   1\n",
       "3      cyberpunk   1\n",
       "4          tried   1\n",
       "5      nextlevel   1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf1 = (data['Text'][1:2]).apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()\n",
    "tf1.columns = ['words','tf']\n",
    "tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hdr</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_aa_carmack</td>\n",
       "      <td>1</td>\n",
       "      <td>4.166415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ray</td>\n",
       "      <td>1</td>\n",
       "      <td>5.035453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cyberpunk</td>\n",
       "      <td>1</td>\n",
       "      <td>5.115496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tried</td>\n",
       "      <td>1</td>\n",
       "      <td>5.808643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nextlevel</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           words  tf       idf\n",
       "0            hdr   1  6.907255\n",
       "1  id_aa_carmack   1  4.166415\n",
       "2            ray   1  5.035453\n",
       "3      cyberpunk   1  5.115496\n",
       "4          tried   1  5.808643\n",
       "5      nextlevel   1  6.907255"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i,word in enumerate(tf1['words']):\n",
    "  tf1.loc[i, 'idf'] = np.log(data.shape[0]/(len(data[data['Text'].str.contains(word)])))\n",
    "\n",
    "tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hdr</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907255</td>\n",
       "      <td>6.907255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_aa_carmack</td>\n",
       "      <td>1</td>\n",
       "      <td>4.166415</td>\n",
       "      <td>4.166415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ray</td>\n",
       "      <td>1</td>\n",
       "      <td>5.035453</td>\n",
       "      <td>5.035453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cyberpunk</td>\n",
       "      <td>1</td>\n",
       "      <td>5.115496</td>\n",
       "      <td>5.115496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tried</td>\n",
       "      <td>1</td>\n",
       "      <td>5.808643</td>\n",
       "      <td>5.808643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nextlevel</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907255</td>\n",
       "      <td>6.907255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           words  tf       idf     tfidf\n",
       "0            hdr   1  6.907255  6.907255\n",
       "1  id_aa_carmack   1  4.166415  4.166415\n",
       "2            ray   1  5.035453  5.035453\n",
       "3      cyberpunk   1  5.115496  5.115496\n",
       "4          tried   1  5.808643  5.808643\n",
       "5      nextlevel   1  6.907255  6.907255"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf1['tfidf'] = tf1['tf'] * tf1['idf']\n",
    "tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1999x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7375 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',\n",
    " stop_words= 'english',ngram_range=(1,1))\n",
    "vect = tfidf.fit_transform(data['Text'])\n",
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1999x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8019 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,1),analyzer = \"word\")\n",
    "data_bow = bow.fit_transform(data['Text'])\n",
    "data_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 (-0.25, 0.75)\n",
       "1                                    (0.0, 0.0)\n",
       "2                                    (0.0, 0.0)\n",
       "3                                    (0.0, 0.0)\n",
       "4    (0.20000000000000004, 0.32222222222222224)\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'][:5].apply(lambda x: TextBlob(x).sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kunalb11 im alien</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_aa_carmack ray cyberpunk hdr nextlevel tried</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>joerogan spotify interview</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gtera27 doge underestimated</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>teslacn congratulation china amazing execution...</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  sentiment\n",
       "0                                  kunalb11 im alien      -0.25\n",
       "1    id_aa_carmack ray cyberpunk hdr nextlevel tried       0.00\n",
       "2                         joerogan spotify interview       0.00\n",
       "3                        gtera27 doge underestimated       0.00\n",
       "4  teslacn congratulation china amazing execution...       0.20"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'] = data['Text'].apply(lambda x: TextBlob(x).sentiment[0] )\n",
    "data[['Text','sentiment']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform emotion mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: future in c:\\users\\vaish\\anaconda3sfw\\lib\\site-packages (0.18.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: future in c:\\users\\vaish\\anaconda3sfw\\lib\\site-packages (0.18.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U future "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re\n",
    "import copy\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import matplotlib\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "from nltk.corpus import twitter_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vaish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      "; \n",
      "; Opinion Lexicon: Positive\n",
      ";\n",
      "; This file contains a list of POSITIVE opinion words (or sentiment words).\n",
      ";\n",
      "; This file and the papers can all be downloaded from \n",
      ";    http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\n",
      ";\n",
      "; If you use this list, please cite one of the following two papers:\n",
      ";\n",
      ";   Minqing Hu and Bing Liu. \"Mining and Summarizing Customer Reviews.\" \n",
      ";       Proceedings of the ACM SIGKDD International Conference on Knowledge \n",
      ";       Discovery and Data Mining (KDD-2004), Aug 22-25, 2004, Seattle, \n",
      ";       Washington, USA, \n",
      ";   Bing Liu, Minqing Hu and Junsheng Cheng. \"Opinion Observer: Analyzing \n",
      ";       and Comparing Opinions on the Web.\" Proceedings of the 14th \n",
      ";       International World Wide Web conference (WWW-2005), May 10-14, \n",
      ";       2005, Chiba, Japan.\n",
      ";\n",
      "; Notes: \n",
      ";    1. The appearance of an opinion word in a sentence does not necessarily  \n",
      ";       mean that the sentence expresses a positive or negative opinion. \n",
      ";       See the paper below:\n",
      ";\n",
      ";       Bing Liu. \"Sentiment Analysis and Subjectivity.\" An chapter in \n",
      ";          Handbook of Natural Language Processing, Second Edition, \n",
      ";          (editors: N. Indurkhya and F. J. Damerau), 2010.\n",
      ";\n",
      ";    2. You will notice many misspelled words in the list. They are not \n",
      ";       mistakes. They are included as these misspelled words appear \n",
      ";       frequently in social media content. \n",
      ";\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      "\n",
      "a+\n",
      "abound\n",
      "abounds\n",
      "abundance\n",
      "abundant\n",
      "accessable\n",
      "accessible\n",
      "acclaim\n",
      "acclaimed\n",
      "acclamation\n",
      "accolade\n",
      "accolades\n",
      "accommodative\n",
      "accomodative\n",
      "accomplish\n",
      "accomplished\n",
      "accomplishment\n",
      "accomplishments\n",
      "accurate\n",
      "accurately\n",
      "achievable\n",
      "achievement\n",
      "achievements\n",
      "achievible\n",
      "acumen\n",
      "adaptable\n",
      "adaptive\n",
      "adequate\n",
      "adjustable\n",
      "admirable\n",
      "admirably\n",
      "admiration\n",
      "admire\n",
      "admirer\n",
      "admiring\n",
      "admiringly\n",
      "adorable\n",
      "adore\n",
      "adored\n",
      "adorer\n",
      "adoring\n",
      "adoringly\n",
      "adroit\n",
      "adroitly\n",
      "adulate\n",
      "adulation\n",
      "adulatory\n",
      "advanced\n",
      "advantage\n",
      "advantageous\n",
      "advantageously\n",
      "advantages\n",
      "adventuresome\n",
      "adventurous\n",
      "advocate\n",
      "advocated\n",
      "advocates\n",
      "affability\n",
      "affable\n",
      "affably\n",
      "affectation\n",
      "affection\n",
      "affectionate\n",
      "affinity\n",
      "affirm\n",
      "affirmation\n",
      "affirmative\n",
      "affluence\n",
      "affluent\n",
      "afford\n",
      "affordable\n",
      "affordably\n",
      "afordable\n",
      "agile\n",
      "agilely\n",
      "agility\n",
      "agreeable\n",
      "agreeableness\n",
      "agreeably\n",
      "all-around\n",
      "alluring\n",
      "alluringly\n",
      "altruistic\n",
      "altruistically\n",
      "amaze\n",
      "amazed\n",
      "amazement\n",
      "amazes\n",
      "amazing\n",
      "amazingly\n",
      "ambitious\n",
      "ambitiously\n",
      "ameliorate\n",
      "amenable\n",
      "amenity\n",
      "amiability\n",
      "amiabily\n",
      "amiable\n",
      "amicability\n",
      "amicable\n",
      "amicably\n",
      "amity\n",
      "ample\n",
      "amply\n",
      "amuse\n",
      "amusing\n",
      "amusingly\n",
      "angel\n",
      "angelic\n",
      "apotheosis\n",
      "appeal\n",
      "appealing\n",
      "applaud\n",
      "appreciable\n",
      "appreciate\n",
      "appreciated\n",
      "appreciates\n",
      "appreciative\n",
      "appreciatively\n",
      "appropriate\n",
      "approval\n",
      "approve\n",
      "ardent\n",
      "ardently\n",
      "ardor\n",
      "articulate\n",
      "aspiration\n",
      "aspirations\n",
      "aspire\n",
      "assurance\n",
      "assurances\n",
      "assure\n",
      "assuredly\n",
      "assuring\n",
      "astonish\n",
      "astonished\n",
      "astonishing\n",
      "astonishingly\n",
      "astonishment\n",
      "astound\n",
      "astounded\n",
      "astounding\n",
      "astoundingly\n",
      "astutely\n",
      "attentive\n",
      "attraction\n",
      "attractive\n",
      "attractively\n",
      "attune\n",
      "audible\n",
      "audibly\n",
      "auspicious\n",
      "authentic\n",
      "authoritative\n",
      "autonomous\n",
      "available\n",
      "aver\n",
      "avid\n",
      "avidly\n",
      "award\n",
      "awarded\n",
      "awards\n",
      "awe\n",
      "awed\n",
      "awesome\n",
      "awesomely\n",
      "awesomeness\n",
      "awestruck\n",
      "awsome\n",
      "backbone\n",
      "balanced\n",
      "bargain\n",
      "beauteous\n",
      "beautiful\n",
      "beautifullly\n",
      "beautifully\n",
      "beautify\n",
      "beauty\n",
      "beckon\n",
      "beckoned\n",
      "beckoning\n",
      "beckons\n",
      "believable\n",
      "believeable\n",
      "beloved\n",
      "benefactor\n",
      "beneficent\n",
      "beneficial\n",
      "beneficially\n",
      "beneficiary\n",
      "benefit\n",
      "benefits\n",
      "benevolence\n",
      "benevolent\n",
      "benifits\n",
      "best\n",
      "best-known\n",
      "best-performing\n",
      "best-selling\n",
      "better\n",
      "better-known\n",
      "better-than-expected\n",
      "beutifully\n",
      "blameless\n",
      "bless\n",
      "blessing\n",
      "bliss\n",
      "blissful\n",
      "blissfully\n",
      "blithe\n",
      "blockbuster\n",
      "bloom\n",
      "blossom\n",
      "bolster\n",
      "bonny\n",
      "bonus\n",
      "bonuses\n",
      "boom\n",
      "booming\n",
      "boost\n",
      "boundless\n",
      "bountiful\n",
      "brainiest\n",
      "brainy\n",
      "brand-new\n",
      "brave\n",
      "bravery\n",
      "bravo\n",
      "breakthrough\n",
      "breakthroughs\n",
      "breathlessness\n",
      "breathtaking\n",
      "breathtakingly\n",
      "breeze\n",
      "bright\n",
      "brighten\n",
      "brighter\n",
      "brightest\n",
      "brilliance\n",
      "brilliances\n",
      "brilliant\n",
      "brilliantly\n",
      "brisk\n",
      "brotherly\n",
      "bullish\n",
      "buoyant\n",
      "cajole\n",
      "calm\n",
      "calming\n",
      "calmness\n",
      "capability\n",
      "capable\n",
      "capably\n",
      "captivate\n",
      "captivating\n",
      "carefree\n",
      "cashback\n",
      "cashbacks\n",
      "catchy\n",
      "celebrate\n",
      "celebrated\n",
      "celebration\n",
      "celebratory\n",
      "champ\n",
      "champion\n",
      "charisma\n",
      "charismatic\n",
      "charitable\n",
      "charm\n",
      "charming\n",
      "charmingly\n",
      "chaste\n",
      "cheaper\n",
      "cheapest\n",
      "cheer\n",
      "cheerful\n",
      "cheery\n",
      "cherish\n",
      "cherished\n",
      "cherub\n",
      "chic\n",
      "chivalrous\n",
      "chivalry\n",
      "civility\n",
      "civilize\n",
      "clarity\n",
      "classic\n",
      "classy\n",
      "clean\n",
      "cleaner\n",
      "cleanest\n",
      "cleanliness\n",
      "cleanly\n",
      "clear\n",
      "clear-cut\n",
      "cleared\n",
      "clearer\n",
      "clearly\n",
      "clears\n",
      "clever\n",
      "cleverly\n",
      "cohere\n",
      "coherence\n",
      "coherent\n",
      "cohesive\n",
      "colorful\n",
      "comely\n",
      "comfort\n",
      "comfortable\n",
      "comfortably\n",
      "comforting\n",
      "comfy\n",
      "commend\n",
      "commendable\n",
      "commendably\n",
      "commitment\n",
      "commodious\n",
      "compact\n",
      "compactly\n",
      "compassion\n",
      "compassionate\n",
      "compatible\n",
      "competitive\n",
      "complement\n",
      "complementary\n",
      "complemented\n",
      "complements\n",
      "compliant\n",
      "compliment\n",
      "complimentary\n",
      "comprehensive\n",
      "conciliate\n",
      "conciliatory\n",
      "concise\n",
      "confidence\n",
      "confident\n",
      "congenial\n",
      "congratulate\n",
      "congratulation\n",
      "congratulations\n",
      "congratulatory\n",
      "conscientious\n",
      "considerate\n",
      "consistent\n",
      "consistently\n",
      "constructive\n",
      "consummate\n",
      "contentment\n",
      "continuity\n",
      "contrasty\n",
      "contribution\n",
      "convenience\n",
      "convenient\n",
      "conveniently\n",
      "convience\n",
      "convienient\n",
      "convient\n",
      "convincing\n",
      "convincingly\n",
      "cool\n",
      "coolest\n",
      "cooperative\n",
      "cooperatively\n",
      "cornerstone\n",
      "correct\n",
      "correctly\n",
      "cost-effective\n",
      "cost-saving\n",
      "counter-attack\n",
      "counter-attacks\n",
      "courage\n",
      "courageous\n",
      "courageously\n",
      "courageousness\n",
      "courteous\n",
      "courtly\n",
      "covenant\n",
      "cozy\n",
      "creative\n",
      "credence\n",
      "credible\n",
      "crisp\n",
      "crisper\n",
      "cure\n",
      "cure-all\n",
      "cushy\n",
      "cute\n",
      "cuteness\n",
      "danke\n",
      "danken\n",
      "daring\n",
      "daringly\n",
      "darling\n",
      "dashing\n",
      "dauntless\n",
      "dawn\n",
      "dazzle\n",
      "dazzled\n",
      "dazzling\n",
      "dead-cheap\n",
      "dead-on\n",
      "decency\n",
      "decent\n",
      "decisive\n",
      "decisiveness\n",
      "dedicated\n",
      "defeat\n",
      "defeated\n",
      "defeating\n",
      "defeats\n",
      "defender\n",
      "deference\n",
      "deft\n",
      "deginified\n",
      "delectable\n",
      "delicacy\n",
      "delicate\n",
      "delicious\n",
      "delight\n",
      "delighted\n",
      "delightful\n",
      "delightfully\n",
      "delightfulness\n",
      "dependable\n",
      "dependably\n",
      "deservedly\n",
      "deserving\n",
      "desirable\n",
      "desiring\n",
      "desirous\n",
      "destiny\n",
      "detachable\n",
      "devout\n",
      "dexterous\n",
      "dexterously\n",
      "dextrous\n",
      "dignified\n",
      "dignify\n",
      "dignity\n",
      "diligence\n",
      "diligent\n",
      "diligently\n",
      "diplomatic\n",
      "dirt-cheap\n",
      "distinction\n",
      "distinctive\n",
      "distinguished\n",
      "diversified\n",
      "divine\n",
      "divinely\n",
      "dominate\n",
      "dominated\n",
      "dominates\n",
      "dote\n",
      "dotingly\n",
      "doubtless\n",
      "dreamland\n",
      "dumbfounded\n",
      "dumbfounding\n",
      "dummy-proof\n",
      "durable\n",
      "dynamic\n",
      "eager\n",
      "eagerly\n",
      "eagerness\n",
      "earnest\n",
      "earnestly\n",
      "earnestness\n",
      "ease\n",
      "eased\n",
      "eases\n",
      "easier\n",
      "easiest\n",
      "easiness\n",
      "easing\n",
      "easy\n",
      "easy-to-use\n",
      "easygoing\n",
      "ebullience\n",
      "ebullient\n",
      "ebulliently\n",
      "ecenomical\n",
      "economical\n",
      "ecstasies\n",
      "ecstasy\n",
      "ecstatic\n",
      "ecstatically\n",
      "edify\n",
      "educated\n",
      "effective\n",
      "effectively\n",
      "effectiveness\n",
      "effectual\n",
      "efficacious\n",
      "efficient\n",
      "efficiently\n",
      "effortless\n",
      "effortlessly\n",
      "effusion\n",
      "effusive\n",
      "effusively\n",
      "effusiveness\n",
      "elan\n",
      "elate\n",
      "elated\n",
      "elatedly\n",
      "elation\n",
      "electrify\n",
      "elegance\n",
      "elegant\n",
      "elegantly\n",
      "elevate\n",
      "elite\n",
      "eloquence\n",
      "eloquent\n",
      "eloquently\n",
      "embolden\n",
      "eminence\n",
      "eminent\n",
      "empathize\n",
      "empathy\n",
      "empower\n",
      "empowerment\n",
      "enchant\n",
      "enchanted\n",
      "enchanting\n",
      "enchantingly\n",
      "encourage\n",
      "encouragement\n",
      "encouraging\n",
      "encouragingly\n",
      "endear\n",
      "endearing\n",
      "endorse\n",
      "endorsed\n",
      "endorsement\n",
      "endorses\n",
      "endorsing\n",
      "energetic\n",
      "energize\n",
      "energy-efficient\n",
      "energy-saving\n",
      "engaging\n",
      "engrossing\n",
      "enhance\n",
      "enhanced\n",
      "enhancement\n",
      "enhances\n",
      "enjoy\n",
      "enjoyable\n",
      "enjoyably\n",
      "enjoyed\n",
      "enjoying\n",
      "enjoyment\n",
      "enjoys\n",
      "enlighten\n",
      "enlightenment\n",
      "enliven\n",
      "ennoble\n",
      "enough\n",
      "enrapt\n",
      "enrapture\n",
      "enraptured\n",
      "enrich\n",
      "enrichment\n",
      "enterprising\n",
      "entertain\n",
      "entertaining\n",
      "entertains\n",
      "enthral\n",
      "enthrall\n",
      "enthralled\n",
      "enthuse\n",
      "enthusiasm\n",
      "enthusiast\n",
      "enthusiastic\n",
      "enthusiastically\n",
      "entice\n",
      "enticed\n",
      "enticing\n",
      "enticingly\n",
      "entranced\n",
      "entrancing\n",
      "entrust\n",
      "enviable\n",
      "enviably\n",
      "envious\n",
      "enviously\n",
      "enviousness\n",
      "envy\n",
      "equitable\n",
      "ergonomical\n",
      "err-free\n",
      "erudite\n",
      "ethical\n",
      "eulogize\n",
      "euphoria\n",
      "euphoric\n",
      "euphorically\n",
      "evaluative\n",
      "evenly\n",
      "eventful\n",
      "everlasting\n",
      "evocative\n",
      "exalt\n",
      "exaltation\n",
      "exalted\n",
      "exaltedly\n",
      "exalting\n",
      "exaltingly\n",
      "examplar\n",
      "examplary\n",
      "excallent\n",
      "exceed\n",
      "exceeded\n",
      "exceeding\n",
      "exceedingly\n",
      "exceeds\n",
      "excel\n",
      "exceled\n",
      "excelent\n",
      "excellant\n",
      "excelled\n",
      "excellence\n",
      "excellency\n",
      "excellent\n",
      "excellently\n",
      "excels\n",
      "exceptional\n",
      "exceptionally\n",
      "excite\n",
      "excited\n",
      "excitedly\n",
      "excitedness\n",
      "excitement\n",
      "excites\n",
      "exciting\n",
      "excitingly\n",
      "exellent\n",
      "exemplar\n",
      "exemplary\n",
      "exhilarate\n",
      "exhilarating\n",
      "exhilaratingly\n",
      "exhilaration\n",
      "exonerate\n",
      "expansive\n",
      "expeditiously\n",
      "expertly\n",
      "exquisite\n",
      "exquisitely\n",
      "extol\n",
      "extoll\n",
      "extraordinarily\n",
      "extraordinary\n",
      "exuberance\n",
      "exuberant\n",
      "exuberantly\n",
      "exult\n",
      "exultant\n",
      "exultation\n",
      "exultingly\n",
      "eye-catch\n",
      "eye-catching\n",
      "eyecatch\n",
      "eyecatching\n",
      "fabulous\n",
      "fabulously\n",
      "facilitate\n",
      "fair\n",
      "fairly\n",
      "fairness\n",
      "faith\n",
      "faithful\n",
      "faithfully\n",
      "faithfulness\n",
      "fame\n",
      "famed\n",
      "famous\n",
      "famously\n",
      "fancier\n",
      "fancinating\n",
      "fancy\n",
      "fanfare\n",
      "fans\n",
      "fantastic\n",
      "fantastically\n",
      "fascinate\n",
      "fascinating\n",
      "fascinatingly\n",
      "fascination\n",
      "fashionable\n",
      "fashionably\n",
      "fast\n",
      "fast-growing\n",
      "fast-paced\n",
      "faster\n",
      "fastest\n",
      "fastest-growing\n",
      "faultless\n",
      "fav\n",
      "fave\n",
      "favor\n",
      "favorable\n",
      "favored\n",
      "favorite\n",
      "favorited\n",
      "favour\n",
      "fearless\n",
      "fearlessly\n",
      "feasible\n",
      "feasibly\n",
      "feat\n",
      "feature-rich\n",
      "fecilitous\n",
      "feisty\n",
      "felicitate\n",
      "felicitous\n",
      "felicity\n",
      "fertile\n",
      "fervent\n",
      "fervently\n",
      "fervid\n",
      "fervidly\n",
      "fervor\n",
      "festive\n",
      "fidelity\n",
      "fiery\n",
      "fine\n",
      "fine-looking\n",
      "finely\n",
      "finer\n",
      "finest\n",
      "firmer\n",
      "first-class\n",
      "first-in-class\n",
      "first-rate\n",
      "flashy\n",
      "flatter\n",
      "flattering\n",
      "flatteringly\n",
      "flawless\n",
      "flawlessly\n",
      "flexibility\n",
      "flexible\n",
      "flourish\n",
      "flourishing\n",
      "fluent\n",
      "flutter\n",
      "fond\n",
      "fondly\n",
      "fondness\n",
      "foolproof\n",
      "foremost\n",
      "foresight\n",
      "formidable\n",
      "fortitude\n",
      "fortuitous\n",
      "fortuitously\n",
      "fortunate\n",
      "fortunately\n",
      "fortune\n",
      "fragrant\n",
      "free\n",
      "freed\n",
      "freedom\n",
      "freedoms\n",
      "fresh\n",
      "fresher\n",
      "freshest\n",
      "friendliness\n",
      "friendly\n",
      "frolic\n",
      "frugal\n",
      "fruitful\n",
      "ftw\n",
      "fulfillment\n",
      "fun\n",
      "futurestic\n",
      "futuristic\n",
      "gaiety\n",
      "gaily\n",
      "gain\n",
      "gained\n",
      "gainful\n",
      "gainfully\n",
      "gaining\n",
      "gains\n",
      "gallant\n",
      "gallantly\n",
      "galore\n",
      "geekier\n",
      "geeky\n",
      "gem\n",
      "gems\n",
      "generosity\n",
      "generous\n",
      "generously\n",
      "genial\n",
      "genius\n",
      "gentle\n",
      "gentlest\n",
      "genuine\n",
      "gifted\n",
      "glad\n",
      "gladden\n",
      "gladly\n",
      "gladness\n",
      "glamorous\n",
      "glee\n",
      "gleeful\n",
      "gleefully\n",
      "glimmer\n",
      "glimmering\n",
      "glisten\n",
      "glistening\n",
      "glitter\n",
      "glitz\n",
      "glorify\n",
      "glorious\n",
      "gloriously\n",
      "glory\n",
      "glow\n",
      "glowing\n",
      "glowingly\n",
      "god-given\n",
      "god-send\n",
      "godlike\n",
      "godsend\n",
      "gold\n",
      "golden\n",
      "good\n",
      "goodly\n",
      "goodness\n",
      "goodwill\n",
      "goood\n",
      "gooood\n",
      "gorgeous\n",
      "gorgeously\n",
      "grace\n",
      "graceful\n",
      "gracefully\n",
      "gracious\n",
      "graciously\n",
      "graciousness\n",
      "grand\n",
      "grandeur\n",
      "grateful\n",
      "gratefully\n",
      "gratification\n",
      "gratified\n",
      "gratifies\n",
      "gratify\n",
      "gratifying\n",
      "gratifyingly\n",
      "gratitude\n",
      "great\n",
      "greatest\n",
      "greatness\n",
      "grin\n",
      "groundbreaking\n",
      "guarantee\n",
      "guidance\n",
      "guiltless\n",
      "gumption\n",
      "gush\n",
      "gusto\n",
      "gutsy\n",
      "hail\n",
      "halcyon\n",
      "hale\n",
      "hallmark\n",
      "hallmarks\n",
      "hallowed\n",
      "handier\n",
      "handily\n",
      "hands-down\n",
      "handsome\n",
      "handsomely\n",
      "handy\n",
      "happier\n",
      "happily\n",
      "happiness\n",
      "happy\n",
      "hard-working\n",
      "hardier\n",
      "hardy\n",
      "harmless\n",
      "harmonious\n",
      "harmoniously\n",
      "harmonize\n",
      "harmony\n",
      "headway\n",
      "heal\n",
      "healthful\n",
      "healthy\n",
      "hearten\n",
      "heartening\n",
      "heartfelt\n",
      "heartily\n",
      "heartwarming\n",
      "heaven\n",
      "heavenly\n",
      "helped\n",
      "helpful\n",
      "helping\n",
      "hero\n",
      "heroic\n",
      "heroically\n",
      "heroine\n",
      "heroize\n",
      "heros\n",
      "high-quality\n",
      "high-spirited\n",
      "hilarious\n",
      "holy\n",
      "homage\n",
      "honest\n",
      "honesty\n",
      "honor\n",
      "honorable\n",
      "honored\n",
      "honoring\n",
      "hooray\n",
      "hopeful\n",
      "hospitable\n",
      "hot\n",
      "hotcake\n",
      "hotcakes\n",
      "hottest\n",
      "hug\n",
      "humane\n",
      "humble\n",
      "humility\n",
      "humor\n",
      "humorous\n",
      "humorously\n",
      "humour\n",
      "humourous\n",
      "ideal\n",
      "idealize\n",
      "ideally\n",
      "idol\n",
      "idolize\n",
      "idolized\n",
      "idyllic\n",
      "illuminate\n",
      "illuminati\n",
      "illuminating\n",
      "illumine\n",
      "illustrious\n",
      "ilu\n",
      "imaculate\n",
      "imaginative\n",
      "immaculate\n",
      "immaculately\n",
      "immense\n",
      "impartial\n",
      "impartiality\n",
      "impartially\n",
      "impassioned\n",
      "impeccable\n",
      "impeccably\n",
      "important\n",
      "impress\n",
      "impressed\n",
      "impresses\n",
      "impressive\n",
      "impressively\n",
      "impressiveness\n",
      "improve\n",
      "improved\n",
      "improvement\n",
      "improvements\n",
      "improves\n",
      "improving\n",
      "incredible\n",
      "incredibly\n",
      "indebted\n",
      "individualized\n",
      "indulgence\n",
      "indulgent\n",
      "industrious\n",
      "inestimable\n",
      "inestimably\n",
      "inexpensive\n",
      "infallibility\n",
      "infallible\n",
      "infallibly\n",
      "influential\n",
      "ingenious\n",
      "ingeniously\n",
      "ingenuity\n",
      "ingenuous\n",
      "ingenuously\n",
      "innocuous\n",
      "innovation\n",
      "innovative\n",
      "inpressed\n",
      "insightful\n",
      "insightfully\n",
      "inspiration\n",
      "inspirational\n",
      "inspire\n",
      "inspiring\n",
      "instantly\n",
      "instructive\n",
      "instrumental\n",
      "integral\n",
      "integrated\n",
      "intelligence\n",
      "intelligent\n",
      "intelligible\n",
      "interesting\n",
      "interests\n",
      "intimacy\n",
      "intimate\n",
      "intricate\n",
      "intrigue\n",
      "intriguing\n",
      "intriguingly\n",
      "intuitive\n",
      "invaluable\n",
      "invaluablely\n",
      "inventive\n",
      "invigorate\n",
      "invigorating\n",
      "invincibility\n",
      "invincible\n",
      "inviolable\n",
      "inviolate\n",
      "invulnerable\n",
      "irreplaceable\n",
      "irreproachable\n",
      "irresistible\n",
      "irresistibly\n",
      "issue-free\n",
      "jaw-droping\n",
      "jaw-dropping\n",
      "jollify\n",
      "jolly\n",
      "jovial\n",
      "joy\n",
      "joyful\n",
      "joyfully\n",
      "joyous\n",
      "joyously\n",
      "jubilant\n",
      "jubilantly\n",
      "jubilate\n",
      "jubilation\n",
      "jubiliant\n",
      "judicious\n",
      "justly\n",
      "keen\n",
      "keenly\n",
      "keenness\n",
      "kid-friendly\n",
      "kindliness\n",
      "kindly\n",
      "kindness\n",
      "knowledgeable\n",
      "kudos\n",
      "large-capacity\n",
      "laud\n",
      "laudable\n",
      "laudably\n",
      "lavish\n",
      "lavishly\n",
      "law-abiding\n",
      "lawful\n",
      "lawfully\n",
      "lead\n",
      "leading\n",
      "leads\n",
      "lean\n",
      "led\n",
      "legendary\n",
      "leverage\n",
      "levity\n",
      "liberate\n",
      "liberation\n",
      "liberty\n",
      "lifesaver\n",
      "light-hearted\n",
      "lighter\n",
      "likable\n",
      "like\n",
      "liked\n",
      "likes\n",
      "liking\n",
      "lionhearted\n",
      "lively\n",
      "logical\n",
      "long-lasting\n",
      "lovable\n",
      "lovably\n",
      "love\n",
      "loved\n",
      "loveliness\n",
      "lovely\n",
      "lover\n",
      "loves\n",
      "loving\n",
      "low-cost\n",
      "low-price\n",
      "low-priced\n",
      "low-risk\n",
      "lower-priced\n",
      "loyal\n",
      "loyalty\n",
      "lucid\n",
      "lucidly\n",
      "luck\n",
      "luckier\n",
      "luckiest\n",
      "luckiness\n",
      "lucky\n",
      "lucrative\n",
      "luminous\n",
      "lush\n",
      "luster\n",
      "lustrous\n",
      "luxuriant\n",
      "luxuriate\n",
      "luxurious\n",
      "luxuriously\n",
      "luxury\n",
      "lyrical\n",
      "magic\n",
      "magical\n",
      "magnanimous\n",
      "magnanimously\n",
      "magnificence\n",
      "magnificent\n",
      "magnificently\n",
      "majestic\n",
      "majesty\n",
      "manageable\n",
      "maneuverable\n",
      "marvel\n",
      "marveled\n",
      "marvelled\n",
      "marvellous\n",
      "marvelous\n",
      "marvelously\n",
      "marvelousness\n",
      "marvels\n",
      "master\n",
      "masterful\n",
      "masterfully\n",
      "masterpiece\n",
      "masterpieces\n",
      "masters\n",
      "mastery\n",
      "matchless\n",
      "mature\n",
      "maturely\n",
      "maturity\n",
      "meaningful\n",
      "memorable\n",
      "merciful\n",
      "mercifully\n",
      "mercy\n",
      "merit\n",
      "meritorious\n",
      "merrily\n",
      "merriment\n",
      "merriness\n",
      "merry\n",
      "mesmerize\n",
      "mesmerized\n",
      "mesmerizes\n",
      "mesmerizing\n",
      "mesmerizingly\n",
      "meticulous\n",
      "meticulously\n",
      "mightily\n",
      "mighty\n",
      "mind-blowing\n",
      "miracle\n",
      "miracles\n",
      "miraculous\n",
      "miraculously\n",
      "miraculousness\n",
      "modern\n",
      "modest\n",
      "modesty\n",
      "momentous\n",
      "monumental\n",
      "monumentally\n",
      "morality\n",
      "motivated\n",
      "multi-purpose\n",
      "navigable\n",
      "neat\n",
      "neatest\n",
      "neatly\n",
      "nice\n",
      "nicely\n",
      "nicer\n",
      "nicest\n",
      "nifty\n",
      "nimble\n",
      "noble\n",
      "nobly\n",
      "noiseless\n",
      "non-violence\n",
      "non-violent\n",
      "notably\n",
      "noteworthy\n",
      "nourish\n",
      "nourishing\n",
      "nourishment\n",
      "novelty\n",
      "nurturing\n",
      "oasis\n",
      "obsession\n",
      "obsessions\n",
      "obtainable\n",
      "openly\n",
      "openness\n",
      "optimal\n",
      "optimism\n",
      "optimistic\n",
      "opulent\n",
      "orderly\n",
      "originality\n",
      "outdo\n",
      "outdone\n",
      "outperform\n",
      "outperformed\n",
      "outperforming\n",
      "outperforms\n",
      "outshine\n",
      "outshone\n",
      "outsmart\n",
      "outstanding\n",
      "outstandingly\n",
      "outstrip\n",
      "outwit\n",
      "ovation\n",
      "overjoyed\n",
      "overtake\n",
      "overtaken\n",
      "overtakes\n",
      "overtaking\n",
      "overtook\n",
      "overture\n",
      "pain-free\n",
      "painless\n",
      "painlessly\n",
      "palatial\n",
      "pamper\n",
      "pampered\n",
      "pamperedly\n",
      "pamperedness\n",
      "pampers\n",
      "panoramic\n",
      "paradise\n",
      "paramount\n",
      "pardon\n",
      "passion\n",
      "passionate\n",
      "passionately\n",
      "patience\n",
      "patient\n",
      "patiently\n",
      "patriot\n",
      "patriotic\n",
      "peace\n",
      "peaceable\n",
      "peaceful\n",
      "peacefully\n",
      "peacekeepers\n",
      "peach\n",
      "peerless\n",
      "pep\n",
      "pepped\n",
      "pepping\n",
      "peppy\n",
      "peps\n",
      "perfect\n",
      "perfection\n",
      "perfectly\n",
      "permissible\n",
      "perseverance\n",
      "persevere\n",
      "personages\n",
      "personalized\n",
      "phenomenal\n",
      "phenomenally\n",
      "picturesque\n",
      "piety\n",
      "pinnacle\n",
      "playful\n",
      "playfully\n",
      "pleasant\n",
      "pleasantly\n",
      "pleased\n",
      "pleases\n",
      "pleasing\n",
      "pleasingly\n",
      "pleasurable\n",
      "pleasurably\n",
      "pleasure\n",
      "plentiful\n",
      "pluses\n",
      "plush\n",
      "plusses\n",
      "poetic\n",
      "poeticize\n",
      "poignant\n",
      "poise\n",
      "poised\n",
      "polished\n",
      "polite\n",
      "politeness\n",
      "popular\n",
      "portable\n",
      "posh\n",
      "positive\n",
      "positively\n",
      "positives\n",
      "powerful\n",
      "powerfully\n",
      "praise\n",
      "praiseworthy\n",
      "praising\n",
      "pre-eminent\n",
      "precious\n",
      "precise\n",
      "precisely\n",
      "preeminent\n",
      "prefer\n",
      "preferable\n",
      "preferably\n",
      "prefered\n",
      "preferes\n",
      "preferring\n",
      "prefers\n",
      "premier\n",
      "prestige\n",
      "prestigious\n",
      "prettily\n",
      "pretty\n",
      "priceless\n",
      "pride\n",
      "principled\n",
      "privilege\n",
      "privileged\n",
      "prize\n",
      "proactive\n",
      "problem-free\n",
      "problem-solver\n",
      "prodigious\n",
      "prodigiously\n",
      "prodigy\n",
      "productive\n",
      "productively\n",
      "proficient\n",
      "proficiently\n",
      "profound\n",
      "profoundly\n",
      "profuse\n",
      "profusion\n",
      "progress\n",
      "progressive\n",
      "prolific\n",
      "prominence\n",
      "prominent\n",
      "promise\n",
      "promised\n",
      "promises\n",
      "promising\n",
      "promoter\n",
      "prompt\n",
      "promptly\n",
      "proper\n",
      "properly\n",
      "propitious\n",
      "propitiously\n",
      "pros\n",
      "prosper\n",
      "prosperity\n",
      "prosperous\n",
      "prospros\n",
      "protect\n",
      "protection\n",
      "protective\n",
      "proud\n",
      "proven\n",
      "proves\n",
      "providence\n",
      "proving\n",
      "prowess\n",
      "prudence\n",
      "prudent\n",
      "prudently\n",
      "punctual\n",
      "pure\n",
      "purify\n",
      "purposeful\n",
      "quaint\n",
      "qualified\n",
      "qualify\n",
      "quicker\n",
      "quiet\n",
      "quieter\n",
      "radiance\n",
      "radiant\n",
      "rapid\n",
      "rapport\n",
      "rapt\n",
      "rapture\n",
      "raptureous\n",
      "raptureously\n",
      "rapturous\n",
      "rapturously\n",
      "rational\n",
      "razor-sharp\n",
      "reachable\n",
      "readable\n",
      "readily\n",
      "ready\n",
      "reaffirm\n",
      "reaffirmation\n",
      "realistic\n",
      "realizable\n",
      "reasonable\n",
      "reasonably\n",
      "reasoned\n",
      "reassurance\n",
      "reassure\n",
      "receptive\n",
      "reclaim\n",
      "recomend\n",
      "recommend\n",
      "recommendation\n",
      "recommendations\n",
      "recommended\n",
      "reconcile\n",
      "reconciliation\n",
      "record-setting\n",
      "recover\n",
      "recovery\n",
      "rectification\n",
      "rectify\n",
      "rectifying\n",
      "redeem\n",
      "redeeming\n",
      "redemption\n",
      "refine\n",
      "refined\n",
      "refinement\n",
      "reform\n",
      "reformed\n",
      "reforming\n",
      "reforms\n",
      "refresh\n",
      "refreshed\n",
      "refreshing\n",
      "refund\n",
      "refunded\n",
      "regal\n",
      "regally\n",
      "regard\n",
      "rejoice\n",
      "rejoicing\n",
      "rejoicingly\n",
      "rejuvenate\n",
      "rejuvenated\n",
      "rejuvenating\n",
      "relaxed\n",
      "relent\n",
      "reliable\n",
      "reliably\n",
      "relief\n",
      "relish\n",
      "remarkable\n",
      "remarkably\n",
      "remedy\n",
      "remission\n",
      "remunerate\n",
      "renaissance\n",
      "renewed\n",
      "renown\n",
      "renowned\n",
      "replaceable\n",
      "reputable\n",
      "reputation\n",
      "resilient\n",
      "resolute\n",
      "resound\n",
      "resounding\n",
      "resourceful\n",
      "resourcefulness\n",
      "respect\n",
      "respectable\n",
      "respectful\n",
      "respectfully\n",
      "respite\n",
      "resplendent\n",
      "responsibly\n",
      "responsive\n",
      "restful\n",
      "restored\n",
      "restructure\n",
      "restructured\n",
      "restructuring\n",
      "retractable\n",
      "revel\n",
      "revelation\n",
      "revere\n",
      "reverence\n",
      "reverent\n",
      "reverently\n",
      "revitalize\n",
      "revival\n",
      "revive\n",
      "revives\n",
      "revolutionary\n",
      "revolutionize\n",
      "revolutionized\n",
      "revolutionizes\n",
      "reward\n",
      "rewarding\n",
      "rewardingly\n",
      "rich\n",
      "richer\n",
      "richly\n",
      "richness\n",
      "right\n",
      "righten\n",
      "righteous\n",
      "righteously\n",
      "righteousness\n",
      "rightful\n",
      "rightfully\n",
      "rightly\n",
      "rightness\n",
      "risk-free\n",
      "robust\n",
      "rock-star\n",
      "rock-stars\n",
      "rockstar\n",
      "rockstars\n",
      "romantic\n",
      "romantically\n",
      "romanticize\n",
      "roomier\n",
      "roomy\n",
      "rosy\n",
      "safe\n",
      "safely\n",
      "sagacity\n",
      "sagely\n",
      "saint\n",
      "saintliness\n",
      "saintly\n",
      "salutary\n",
      "salute\n",
      "sane\n",
      "satisfactorily\n",
      "satisfactory\n",
      "satisfied\n",
      "satisfies\n",
      "satisfy\n",
      "satisfying\n",
      "satisified\n",
      "saver\n",
      "savings\n",
      "savior\n",
      "savvy\n",
      "scenic\n",
      "seamless\n",
      "seasoned\n",
      "secure\n",
      "securely\n",
      "selective\n",
      "self-determination\n",
      "self-respect\n",
      "self-satisfaction\n",
      "self-sufficiency\n",
      "self-sufficient\n",
      "sensation\n",
      "sensational\n",
      "sensationally\n",
      "sensations\n",
      "sensible\n",
      "sensibly\n",
      "sensitive\n",
      "serene\n",
      "serenity\n",
      "sexy\n",
      "sharp\n",
      "sharper\n",
      "sharpest\n",
      "shimmering\n",
      "shimmeringly\n",
      "shine\n",
      "shiny\n",
      "significant\n",
      "silent\n",
      "simpler\n",
      "simplest\n",
      "simplified\n",
      "simplifies\n",
      "simplify\n",
      "simplifying\n",
      "sincere\n",
      "sincerely\n",
      "sincerity\n",
      "skill\n",
      "skilled\n",
      "skillful\n",
      "skillfully\n",
      "slammin\n",
      "sleek\n",
      "slick\n",
      "smart\n",
      "smarter\n",
      "smartest\n",
      "smartly\n",
      "smile\n",
      "smiles\n",
      "smiling\n",
      "smilingly\n",
      "smitten\n",
      "smooth\n",
      "smoother\n",
      "smoothes\n",
      "smoothest\n",
      "smoothly\n",
      "snappy\n",
      "snazzy\n",
      "sociable\n",
      "soft\n",
      "softer\n",
      "solace\n",
      "solicitous\n",
      "solicitously\n",
      "solid\n",
      "solidarity\n",
      "soothe\n",
      "soothingly\n",
      "sophisticated\n",
      "soulful\n",
      "soundly\n",
      "soundness\n",
      "spacious\n",
      "sparkle\n",
      "sparkling\n",
      "spectacular\n",
      "spectacularly\n",
      "speedily\n",
      "speedy\n",
      "spellbind\n",
      "spellbinding\n",
      "spellbindingly\n",
      "spellbound\n",
      "spirited\n",
      "spiritual\n",
      "splendid\n",
      "splendidly\n",
      "splendor\n",
      "spontaneous\n",
      "sporty\n",
      "spotless\n",
      "sprightly\n",
      "stability\n",
      "stabilize\n",
      "stable\n",
      "stainless\n",
      "standout\n",
      "state-of-the-art\n",
      "stately\n",
      "statuesque\n",
      "staunch\n",
      "staunchly\n",
      "staunchness\n",
      "steadfast\n",
      "steadfastly\n",
      "steadfastness\n",
      "steadiest\n",
      "steadiness\n",
      "steady\n",
      "stellar\n",
      "stellarly\n",
      "stimulate\n",
      "stimulates\n",
      "stimulating\n",
      "stimulative\n",
      "stirringly\n",
      "straighten\n",
      "straightforward\n",
      "streamlined\n",
      "striking\n",
      "strikingly\n",
      "striving\n",
      "strong\n",
      "stronger\n",
      "strongest\n",
      "stunned\n",
      "stunning\n",
      "stunningly\n",
      "stupendous\n",
      "stupendously\n",
      "sturdier\n",
      "sturdy\n",
      "stylish\n",
      "stylishly\n",
      "stylized\n",
      "suave\n",
      "suavely\n",
      "sublime\n",
      "subsidize\n",
      "subsidized\n",
      "subsidizes\n",
      "subsidizing\n",
      "substantive\n",
      "succeed\n",
      "succeeded\n",
      "succeeding\n",
      "succeeds\n",
      "succes\n",
      "success\n",
      "successes\n",
      "successful\n",
      "successfully\n",
      "suffice\n",
      "sufficed\n",
      "suffices\n",
      "sufficient\n",
      "sufficiently\n",
      "suitable\n",
      "sumptuous\n",
      "sumptuously\n",
      "sumptuousness\n",
      "super\n",
      "superb\n",
      "superbly\n",
      "superior\n",
      "superiority\n",
      "supple\n",
      "support\n",
      "supported\n",
      "supporter\n",
      "supporting\n",
      "supportive\n",
      "supports\n",
      "supremacy\n",
      "supreme\n",
      "supremely\n",
      "supurb\n",
      "supurbly\n",
      "surmount\n",
      "surpass\n",
      "surreal\n",
      "survival\n",
      "survivor\n",
      "sustainability\n",
      "sustainable\n",
      "swank\n",
      "swankier\n",
      "swankiest\n",
      "swanky\n",
      "sweeping\n",
      "sweet\n",
      "sweeten\n",
      "sweetheart\n",
      "sweetly\n",
      "sweetness\n",
      "swift\n",
      "swiftness\n",
      "talent\n",
      "talented\n",
      "talents\n",
      "tantalize\n",
      "tantalizing\n",
      "tantalizingly\n",
      "tempt\n",
      "tempting\n",
      "temptingly\n",
      "tenacious\n",
      "tenaciously\n",
      "tenacity\n",
      "tender\n",
      "tenderly\n",
      "terrific\n",
      "terrifically\n",
      "thank\n",
      "thankful\n",
      "thinner\n",
      "thoughtful\n",
      "thoughtfully\n",
      "thoughtfulness\n",
      "thrift\n",
      "thrifty\n",
      "thrill\n",
      "thrilled\n",
      "thrilling\n",
      "thrillingly\n",
      "thrills\n",
      "thrive\n",
      "thriving\n",
      "thumb-up\n",
      "thumbs-up\n",
      "tickle\n",
      "tidy\n",
      "time-honored\n",
      "timely\n",
      "tingle\n",
      "titillate\n",
      "titillating\n",
      "titillatingly\n",
      "togetherness\n",
      "tolerable\n",
      "toll-free\n",
      "top\n",
      "top-notch\n",
      "top-quality\n",
      "topnotch\n",
      "tops\n",
      "tough\n",
      "tougher\n",
      "toughest\n",
      "traction\n",
      "tranquil\n",
      "tranquility\n",
      "transparent\n",
      "treasure\n",
      "tremendously\n",
      "trendy\n",
      "triumph\n",
      "triumphal\n",
      "triumphant\n",
      "triumphantly\n",
      "trivially\n",
      "trophy\n",
      "trouble-free\n",
      "trump\n",
      "trumpet\n",
      "trust\n",
      "trusted\n",
      "trusting\n",
      "trustingly\n",
      "trustworthiness\n",
      "trustworthy\n",
      "trusty\n",
      "truthful\n",
      "truthfully\n",
      "truthfulness\n",
      "twinkly\n",
      "ultra-crisp\n",
      "unabashed\n",
      "unabashedly\n",
      "unaffected\n",
      "unassailable\n",
      "unbeatable\n",
      "unbiased\n",
      "unbound\n",
      "uncomplicated\n",
      "unconditional\n",
      "undamaged\n",
      "undaunted\n",
      "understandable\n",
      "undisputable\n",
      "undisputably\n",
      "undisputed\n",
      "unencumbered\n",
      "unequivocal\n",
      "unequivocally\n",
      "unfazed\n",
      "unfettered\n",
      "unforgettable\n",
      "unity\n",
      "unlimited\n",
      "unmatched\n",
      "unparalleled\n",
      "unquestionable\n",
      "unquestionably\n",
      "unreal\n",
      "unrestricted\n",
      "unrivaled\n",
      "unselfish\n",
      "unwavering\n",
      "upbeat\n",
      "upgradable\n",
      "upgradeable\n",
      "upgraded\n",
      "upheld\n",
      "uphold\n",
      "uplift\n",
      "uplifting\n",
      "upliftingly\n",
      "upliftment\n",
      "upscale\n",
      "usable\n",
      "useable\n",
      "useful\n",
      "user-friendly\n",
      "user-replaceable\n",
      "valiant\n",
      "valiantly\n",
      "valor\n",
      "valuable\n",
      "variety\n",
      "venerate\n",
      "verifiable\n",
      "veritable\n",
      "versatile\n",
      "versatility\n",
      "vibrant\n",
      "vibrantly\n",
      "victorious\n",
      "victory\n",
      "viewable\n",
      "vigilance\n",
      "vigilant\n",
      "virtue\n",
      "virtuous\n",
      "virtuously\n",
      "visionary\n",
      "vivacious\n",
      "vivid\n",
      "vouch\n",
      "vouchsafe\n",
      "warm\n",
      "warmer\n",
      "warmhearted\n",
      "warmly\n",
      "warmth\n",
      "wealthy\n",
      "welcome\n",
      "well\n",
      "well-backlit\n",
      "well-balanced\n",
      "well-behaved\n",
      "well-being\n",
      "well-bred\n",
      "well-connected\n",
      "well-educated\n",
      "well-established\n",
      "well-informed\n",
      "well-intentioned\n",
      "well-known\n",
      "well-made\n",
      "well-managed\n",
      "well-mannered\n",
      "well-positioned\n",
      "well-received\n",
      "well-regarded\n",
      "well-rounded\n",
      "well-run\n",
      "well-wishers\n",
      "wellbeing\n",
      "whoa\n",
      "wholeheartedly\n",
      "wholesome\n",
      "whooa\n",
      "whoooa\n",
      "wieldy\n",
      "willing\n",
      "willingly\n",
      "willingness\n",
      "win\n",
      "windfall\n",
      "winnable\n",
      "winner\n",
      "winners\n",
      "winning\n",
      "wins\n",
      "wisdom\n",
      "wise\n",
      "wisely\n",
      "witty\n",
      "won\n",
      "wonder\n",
      "wonderful\n",
      "wonderfully\n",
      "wonderous\n",
      "wonderously\n",
      "wonders\n",
      "wondrous\n",
      "woo\n",
      "work\n",
      "workable\n",
      "worked\n",
      "works\n",
      "world-famous\n",
      "worth\n",
      "worth-while\n",
      "worthiness\n",
      "worthwhile\n",
      "worthy\n",
      "wow\n",
      "wowed\n",
      "wowing\n",
      "wows\n",
      "yay\n",
      "youthful\n",
      "zeal\n",
      "zenith\n",
      "zest\n",
      "zippy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with codecs.open(\"positive-words.txt\", \"r\", encoding=\"utf-8\") as p:\n",
    "    pos = p.read()\n",
    "    print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mtwitter_samples\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('twitter_samples')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/twitter_samples\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\vaish/nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3sfw\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3sfw\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mtwitter_samples\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('twitter_samples')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/twitter_samples.zip/twitter_samples/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\vaish/nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-5952e3597d1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtwitter_samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpositive_tweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwitter_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'positive_tweets.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mnegative_tweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwitter_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'negative_tweets.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwitter_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tweets.20150430-223406.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3sfw\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3sfw\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3sfw\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3sfw\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mtwitter_samples\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('twitter_samples')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/twitter_samples\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\vaish/nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import twitter_samples\n",
    "\n",
    "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "text = twitter_samples.strings('tweets.20150430-223406.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mtwitter_samples\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('twitter_samples')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/twitter_samples\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\vaish/nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3sfw\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3sfw\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mtwitter_samples\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('twitter_samples')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/twitter_samples.zip/twitter_samples/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\vaish/nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ef027d42805f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtwitter_samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpositive_tweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwitter_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'positive_tweets.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mnegative_tweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwitter_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'negative_tweets.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwitter_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tweets.20150430-223406.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3sfw\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3sfw\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3sfw\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3sfw\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mtwitter_samples\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('twitter_samples')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/twitter_samples\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\vaish/nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import twitter_samples\n",
    "\n",
    "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "text = twitter_samples.strings('tweets.20150430-223406.json')\n",
    "tweet_tokens = twitter_samples.tokenized('positive_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mtwitter_samples\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('twitter_samples')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/twitter_samples\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\vaish/nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3sfw\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3sfw\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mtwitter_samples\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('twitter_samples')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/twitter_samples.zip/twitter_samples/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\vaish/nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-69e9268b4f08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtwitter_samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpositive_tweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwitter_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'positive_tweets.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mnegative_tweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwitter_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'negative_tweets.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwitter_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tweets.20150430-223406.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3sfw\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3sfw\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3sfw\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3sfw\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mtwitter_samples\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('twitter_samples')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/twitter_samples\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\vaish/nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\anaconda3sfw\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\vaish\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import twitter_samples\n",
    "\n",
    "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "text = twitter_samples.strings('tweets.20150430-223406.json')\n",
    "tweet_tokens = twitter_samples.tokenized('positive_tweets.json')[0]\n",
    "\n",
    "print(tweet_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\vaish\\anaconda3sfw\\lib\\site-packages (4.9.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\vaish\\anaconda3sfw\\lib\\site-packages (from beautifulsoup4) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as ticker\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_pages = 2\n",
    "\n",
    "def get_data(pageNo):  \n",
    "    headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "\n",
    "    r = requests.get('https://www.amazon.in/gp/bestsellers/books/ref=zg_bs_pg_'+str(pageNo)+'?ie=UTF8&pg='+str(pageNo), headers=headers)#, proxies=proxies)\n",
    "    content = r.content\n",
    "    soup = BeautifulSoup(content)\n",
    "    #print(soup)\n",
    "\n",
    "    alls = []\n",
    "    for d in soup.findAll('div', attrs={'class':'a-section a-spacing-none aok-relative'}):\n",
    "        #print(d)\n",
    "        name = d.find('span', attrs={'class':'zg-text-center-align'})\n",
    "        n = name.find_all('img', alt=True)\n",
    "        #print(n[0]['alt'])\n",
    "        author = d.find('a', attrs={'class':'a-size-small a-link-child'})\n",
    "        rating = d.find('span', attrs={'class':'a-icon-alt'})\n",
    "        users_rated = d.find('a', attrs={'class':'a-size-small a-link-normal'})\n",
    "        price = d.find('span', attrs={'class':'p13n-sc-price'})\n",
    "\n",
    "        all1=[]\n",
    "\n",
    "        if name is not None:\n",
    "            #print(n[0]['alt'])\n",
    "            all1.append(n[0]['alt'])\n",
    "        else:\n",
    "            all1.append(\"unknown-product\")\n",
    "\n",
    "        if author is not None:\n",
    "            #print(author.text)\n",
    "            all1.append(author.text)\n",
    "        elif author is None:\n",
    "            author = d.find('span', attrs={'class':'a-size-small a-color-base'})\n",
    "            if author is not None:\n",
    "                all1.append(author.text)\n",
    "            else:    \n",
    "                all1.append('0')\n",
    "\n",
    "        if rating is not None:\n",
    "            #print(rating.text)\n",
    "            all1.append(rating.text)\n",
    "        else:\n",
    "            all1.append('-1')\n",
    "        if users_rated is not None:\n",
    "            #print(price.text)\n",
    "            all1.append(users_rated.text)\n",
    "        else:\n",
    "            all1.append('0')     \n",
    "\n",
    "        if price is not None:\n",
    "            #print(price.text)\n",
    "            all1.append(price.text)\n",
    "        else:\n",
    "            all1.append('0')\n",
    "        alls.append(all1)    \n",
    "    return alls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(1, no_pages+1):\n",
    "    results.append(get_data(i))\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "df = pd.DataFrame(flatten(results),columns=['Book Name','Author','Rating','Customers_Rated', 'Price'])\n",
    "df.to_csv('amazon_products.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"amazon_products.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Customers_Rated</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Book Name, Author, Rating, Customers_Rated, Price]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Customers_Rated</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Book Name, Author, Rating, Customers_Rated, Price]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rating'] = df['Rating'].apply(lambda x: x.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Customers_Rated</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Book Name, Author, Rating, Customers_Rated, Price]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rating'] = pd.to_numeric(df['Rating'])\n",
    "df[\"Price\"] = df[\"Price\"].str.replace('₹', '')\n",
    "df[\"Price\"] = df[\"Price\"].str.replace(',', '')\n",
    "df['Price'] = df['Price'].apply(lambda x: x.split('.')[0])\n",
    "df['Price'] = df['Price'].astype(int)\n",
    "df[\"Customers_Rated\"] = df[\"Customers_Rated\"].str.replace(',', '')\n",
    "df['Customers_Rated'] = pd.to_numeric(df['Customers_Rated'], errors='ignore')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Book Name          object\n",
       "Author             object\n",
       "Rating              int64\n",
       "Customers_Rated     int64\n",
       "Price               int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Book Name          0\n",
       "Author             0\n",
       "Rating             0\n",
       "Customers_Rated    0\n",
       "Price              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace(str(0), np.nan, inplace=True)\n",
    "df.replace(0, np.nan, inplace=True)\n",
    "count_nan = len(df) - df.count()\n",
    "count_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Customers_Rated</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Book Name, Author, Rating, Customers_Rated, Price]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.sort_values([\"Price\"], axis=0, ascending=False)[:15]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.transform import dodge\n",
    "import math\n",
    "from bokeh.io import curdoc\n",
    "curdoc().clear()\n",
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "from bokeh.layouts import row\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.transform import factor_cmap\n",
    "from bokeh.models import Legend\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"4140303a-3d1a-4030-ab9a-ae5df848a1e6\" data-root-id=\"1002\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"78c48596-b7b0-4a75-83a3-87e0a39b5ed0\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1013\"}],\"center\":[{\"id\":\"1015\"},{\"id\":\"1019\"}],\"left\":[{\"id\":\"1016\"}],\"plot_height\":550,\"plot_width\":800,\"renderers\":[{\"id\":\"1024\"}],\"title\":{\"id\":\"1003\"},\"toolbar\":{\"id\":\"1020\"},\"toolbar_location\":null,\"x_range\":{\"id\":\"1005\"},\"x_scale\":{\"id\":\"1009\"},\"y_range\":{\"id\":\"1007\"},\"y_scale\":{\"id\":\"1011\"}},\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"start\":0},\"id\":\"1007\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1031\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"formatter\":{\"id\":\"1028\"},\"major_label_orientation\":1.5707963267948966,\"ticker\":{\"id\":\"1014\"}},\"id\":\"1013\",\"type\":\"CategoricalAxis\"},{\"attributes\":{},\"id\":\"1028\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"CategoricalScale\"},{\"attributes\":{},\"id\":\"1014\",\"type\":\"CategoricalTicker\"},{\"attributes\":{},\"id\":\"1030\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1011\",\"type\":\"LinearScale\"},{\"attributes\":{\"axis\":{\"id\":\"1013\"},\"grid_line_color\":null,\"ticker\":null},\"id\":\"1015\",\"type\":\"Grid\"},{\"attributes\":{\"formatter\":{\"id\":\"1030\"},\"ticker\":{\"id\":\"1017\"}},\"id\":\"1016\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1017\",\"type\":\"BasicTicker\"},{\"attributes\":{\"axis\":{\"id\":\"1016\"},\"dimension\":1,\"ticker\":null},\"id\":\"1019\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1032\",\"type\":\"Selection\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\"},\"id\":\"1020\",\"type\":\"Toolbar\"},{\"attributes\":{\"data\":{\"top\":{\"__ndarray__\":\"\",\"dtype\":\"int32\",\"order\":\"little\",\"shape\":[0]},\"x\":[]},\"selected\":{\"id\":\"1032\"},\"selection_policy\":{\"id\":\"1031\"}},\"id\":\"1021\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"top\"},\"width\":{\"value\":0.9},\"x\":{\"field\":\"x\"}},\"id\":\"1023\",\"type\":\"VBar\"},{\"attributes\":{\"data_source\":{\"id\":\"1021\"},\"glyph\":{\"id\":\"1022\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1023\"},\"selection_glyph\":null,\"view\":{\"id\":\"1025\"}},\"id\":\"1024\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"top\"},\"width\":{\"value\":0.9},\"x\":{\"field\":\"x\"}},\"id\":\"1022\",\"type\":\"VBar\"},{\"attributes\":{\"source\":{\"id\":\"1021\"}},\"id\":\"1025\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1005\",\"type\":\"FactorRange\"},{\"attributes\":{\"text\":\"Authors Highest Priced Book\"},\"id\":\"1003\",\"type\":\"Title\"}],\"root_ids\":[\"1002\"]},\"title\":\"Bokeh Application\",\"version\":\"2.1.1\"}};\n",
       "  var render_items = [{\"docid\":\"78c48596-b7b0-4a75-83a3-87e0a39b5ed0\",\"root_ids\":[\"1002\"],\"roots\":{\"1002\":\"4140303a-3d1a-4030-ab9a-ae5df848a1e6\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1002"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Customers_Rated</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Book Name, Author, Rating, Customers_Rated, Price]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = figure(x_range=data.iloc[:,1], plot_width=800, plot_height=550, title=\"Authors Highest Priced Book\", toolbar_location=None, tools=\"\")\n",
    "\n",
    "p.vbar(x=data.iloc[:,1], top=data.iloc[:,4], width=0.9)\n",
    "\n",
    "p.xgrid.grid_line_color = None\n",
    "p.y_range.start = 0\n",
    "p.xaxis.major_label_orientation = math.pi/2\n",
    "show(p)\n",
    "data = df[df['Customers_Rated'] > 1000]\n",
    "data = data.sort_values(['Rating'],axis=0, ascending=False)[:15]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"d1f707f0-d12a-4c40-aefc-731ba6bfe703\" data-root-id=\"1075\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"dd8f80f6-d834-4d72-b309-280742d34efb\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1086\"}],\"center\":[{\"id\":\"1088\"},{\"id\":\"1092\"}],\"left\":[{\"id\":\"1089\"}],\"plot_width\":800,\"renderers\":[{\"id\":\"1097\"}],\"title\":{\"id\":\"1076\"},\"toolbar\":{\"id\":\"1093\"},\"toolbar_location\":null,\"x_range\":{\"id\":\"1078\"},\"x_scale\":{\"id\":\"1082\"},\"y_range\":{\"id\":\"1080\"},\"y_scale\":{\"id\":\"1084\"}},\"id\":\"1075\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"formatter\":{\"id\":\"1108\"},\"major_label_orientation\":1.5707963267948966,\"ticker\":{\"id\":\"1087\"}},\"id\":\"1086\",\"type\":\"CategoricalAxis\"},{\"attributes\":{},\"id\":\"1082\",\"type\":\"CategoricalScale\"},{\"attributes\":{\"axis\":{\"id\":\"1089\"},\"dimension\":1,\"ticker\":null},\"id\":\"1092\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1110\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1087\",\"type\":\"CategoricalTicker\"},{\"attributes\":{\"text\":\"Top Rated Books with more than 1000 Customers Rating\"},\"id\":\"1076\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1090\",\"type\":\"BasicTicker\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\"},\"id\":\"1093\",\"type\":\"Toolbar\"},{\"attributes\":{\"data\":{\"top\":[],\"x\":[]},\"selected\":{\"id\":\"1112\"},\"selection_policy\":{\"id\":\"1111\"}},\"id\":\"1094\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"start\":0},\"id\":\"1080\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1078\",\"type\":\"FactorRange\"},{\"attributes\":{},\"id\":\"1084\",\"type\":\"LinearScale\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"top\"},\"width\":{\"value\":0.9},\"x\":{\"field\":\"x\"}},\"id\":\"1096\",\"type\":\"VBar\"},{\"attributes\":{\"data_source\":{\"id\":\"1094\"},\"glyph\":{\"id\":\"1095\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1096\"},\"selection_glyph\":null,\"view\":{\"id\":\"1098\"}},\"id\":\"1097\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"source\":{\"id\":\"1094\"}},\"id\":\"1098\",\"type\":\"CDSView\"},{\"attributes\":{\"axis\":{\"id\":\"1086\"},\"grid_line_color\":null,\"ticker\":null},\"id\":\"1088\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1111\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"top\"},\"width\":{\"value\":0.9},\"x\":{\"field\":\"x\"}},\"id\":\"1095\",\"type\":\"VBar\"},{\"attributes\":{},\"id\":\"1112\",\"type\":\"Selection\"},{\"attributes\":{\"formatter\":{\"id\":\"1110\"},\"ticker\":{\"id\":\"1090\"}},\"id\":\"1089\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1108\",\"type\":\"CategoricalTickFormatter\"}],\"root_ids\":[\"1075\"]},\"title\":\"Bokeh Application\",\"version\":\"2.1.1\"}};\n",
       "  var render_items = [{\"docid\":\"dd8f80f6-d834-4d72-b309-280742d34efb\",\"root_ids\":[\"1075\"],\"roots\":{\"1075\":\"d1f707f0-d12a-4c40-aefc-731ba6bfe703\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1075"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"e9ddb127-1a72-442b-b128-b3018cf0bf92\" data-root-id=\"1155\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"28079f25-9d6f-4a6f-9af1-aaa596489cf2\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1166\"}],\"center\":[{\"id\":\"1168\"},{\"id\":\"1172\"}],\"left\":[{\"id\":\"1169\"}],\"plot_width\":800,\"renderers\":[{\"id\":\"1177\"}],\"title\":{\"id\":\"1156\"},\"toolbar\":{\"id\":\"1173\"},\"toolbar_location\":null,\"x_range\":{\"id\":\"1158\"},\"x_scale\":{\"id\":\"1162\"},\"y_range\":{\"id\":\"1160\"},\"y_scale\":{\"id\":\"1164\"}},\"id\":\"1155\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"top\"},\"width\":{\"value\":0.9},\"x\":{\"field\":\"x\"}},\"id\":\"1176\",\"type\":\"VBar\"},{\"attributes\":{\"data_source\":{\"id\":\"1174\"},\"glyph\":{\"id\":\"1175\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1176\"},\"selection_glyph\":null,\"view\":{\"id\":\"1178\"}},\"id\":\"1177\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"source\":{\"id\":\"1174\"}},\"id\":\"1178\",\"type\":\"CDSView\"},{\"attributes\":{\"text\":\"Top Rated Books with more than 1000 Customers Rating\"},\"id\":\"1156\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1198\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"formatter\":{\"id\":\"1195\"},\"major_label_orientation\":1.5707963267948966,\"ticker\":{\"id\":\"1167\"}},\"id\":\"1166\",\"type\":\"CategoricalAxis\"},{\"attributes\":{},\"id\":\"1199\",\"type\":\"Selection\"},{\"attributes\":{\"start\":0},\"id\":\"1160\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1167\",\"type\":\"CategoricalTicker\"},{\"attributes\":{\"axis\":{\"id\":\"1166\"},\"grid_line_color\":null,\"ticker\":null},\"id\":\"1168\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1195\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{\"formatter\":{\"id\":\"1197\"},\"ticker\":{\"id\":\"1170\"}},\"id\":\"1169\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1170\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1197\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"axis\":{\"id\":\"1169\"},\"dimension\":1,\"ticker\":null},\"id\":\"1172\",\"type\":\"Grid\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\"},\"id\":\"1173\",\"type\":\"Toolbar\"},{\"attributes\":{\"data\":{\"top\":[],\"x\":[]},\"selected\":{\"id\":\"1199\"},\"selection_policy\":{\"id\":\"1198\"}},\"id\":\"1174\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"top\"},\"width\":{\"value\":0.9},\"x\":{\"field\":\"x\"}},\"id\":\"1175\",\"type\":\"VBar\"},{\"attributes\":{},\"id\":\"1164\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1162\",\"type\":\"CategoricalScale\"},{\"attributes\":{},\"id\":\"1158\",\"type\":\"FactorRange\"}],\"root_ids\":[\"1155\"]},\"title\":\"Bokeh Application\",\"version\":\"2.1.1\"}};\n",
       "  var render_items = [{\"docid\":\"28079f25-9d6f-4a6f-9af1-aaa596489cf2\",\"root_ids\":[\"1155\"],\"roots\":{\"1155\":\"e9ddb127-1a72-442b-b128-b3018cf0bf92\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1155"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = figure(x_range=data.iloc[:,0], plot_width=800, plot_height=600, title=\"Top Rated Books with more than 1000 Customers Rating\", toolbar_location=None, tools=\"\")\n",
    "\n",
    "p.vbar(x=data.iloc[:,0], top=data.iloc[:,2], width=0.9)\n",
    "\n",
    "p.xgrid.grid_line_color = None\n",
    "p.y_range.start = 0\n",
    "p.xaxis.major_label_orientation = math.pi/2\n",
    "show(p)\n",
    "p = figure(x_range=data.iloc[:,1], plot_width=800, plot_height=600, title=\"Top Rated Books with more than 1000 Customers Rating\", toolbar_location=None, tools=\"\")\n",
    "\n",
    "p.vbar(x=data.iloc[:,1], top=data.iloc[:,2], width=0.9)\n",
    "\n",
    "p.xgrid.grid_line_color = None\n",
    "p.y_range.start = 0\n",
    "p.xaxis.major_label_orientation = math.pi/2\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Customers_Rated</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Book Name, Author, Rating, Customers_Rated, Price]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.sort_values([\"Customers_Rated\"], axis=0, ascending=False)[:20]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.transform import factor_cmap\n",
    "from bokeh.models import Legend\n",
    "from bokeh.palettes import Dark2_5 as palette\n",
    "import itertools\n",
    "from bokeh.palettes import d3\n",
    "#colors has a list of colors which can be used in plots\n",
    "colors = itertools.cycle(palette)\n",
    "\n",
    "palette = d3['Category20'][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n"
     ]
    }
   ],
   "source": [
    "index_cmap = factor_cmap('Author', palette=palette,\n",
    "                         factors=data[\"Author\"])\n",
    "p = figure(plot_width=700, plot_height=700, title = \"Top Authors: Rating vs. Customers Rated\")\n",
    "p.scatter('Rating','Customers_Rated',source=data,fill_alpha=0.6, fill_color=index_cmap,size=20,legend='Author')\n",
    "p.xaxis.axis_label = 'RATING'\n",
    "p.yaxis.axis_label = 'CUSTOMERS RATED'\n",
    "p.legend.location = 'top_left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"ccfb83ad-7287-4abd-973d-025260f2dd73\" data-root-id=\"1243\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"be7f1599-965e-4a1b-ae6f-e422815ed50f\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1254\"}],\"center\":[{\"id\":\"1257\"},{\"id\":\"1261\"},{\"id\":\"1290\"}],\"left\":[{\"id\":\"1258\"}],\"plot_height\":700,\"plot_width\":700,\"renderers\":[{\"id\":\"1280\"}],\"title\":{\"id\":\"1244\"},\"toolbar\":{\"id\":\"1269\"},\"x_range\":{\"id\":\"1246\"},\"x_scale\":{\"id\":\"1250\"},\"y_range\":{\"id\":\"1248\"},\"y_scale\":{\"id\":\"1252\"}},\"id\":\"1243\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.6},\"fill_color\":{\"field\":\"Author\",\"transform\":{\"id\":\"1242\"}},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":20},\"x\":{\"field\":\"Rating\"},\"y\":{\"field\":\"Customers_Rated\"}},\"id\":\"1278\",\"type\":\"Scatter\"},{\"attributes\":{\"items\":[{\"id\":\"1291\"}],\"location\":\"top_left\"},\"id\":\"1290\",\"type\":\"Legend\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1262\"},{\"id\":\"1263\"},{\"id\":\"1264\"},{\"id\":\"1265\"},{\"id\":\"1266\"},{\"id\":\"1267\"}]},\"id\":\"1269\",\"type\":\"Toolbar\"},{\"attributes\":{\"axis_label\":\"CUSTOMERS RATED\",\"formatter\":{\"id\":\"1286\"},\"ticker\":{\"id\":\"1259\"}},\"id\":\"1258\",\"type\":\"LinearAxis\"},{\"attributes\":{\"axis\":{\"id\":\"1254\"},\"ticker\":null},\"id\":\"1257\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1263\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1262\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1259\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1284\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1250\",\"type\":\"LinearScale\"},{\"attributes\":{\"overlay\":{\"id\":\"1268\"}},\"id\":\"1264\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1265\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1255\",\"type\":\"BasicTicker\"},{\"attributes\":{\"factors\":[],\"palette\":[\"#1f77b4\",\"#aec7e8\",\"#ff7f0e\",\"#ffbb78\",\"#2ca02c\",\"#98df8a\",\"#d62728\",\"#ff9896\",\"#9467bd\",\"#c5b0d5\",\"#8c564b\",\"#c49c94\",\"#e377c2\",\"#f7b6d2\",\"#7f7f7f\",\"#c7c7c7\",\"#bcbd22\",\"#dbdb8d\",\"#17becf\",\"#9edae5\"]},\"id\":\"1242\",\"type\":\"CategoricalColorMapper\"},{\"attributes\":{},\"id\":\"1248\",\"type\":\"DataRange1d\"},{\"attributes\":{\"data_source\":{\"id\":\"1276\"},\"glyph\":{\"id\":\"1278\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1279\"},\"selection_glyph\":null,\"view\":{\"id\":\"1281\"}},\"id\":\"1280\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1267\",\"type\":\"HelpTool\"},{\"attributes\":{},\"id\":\"1287\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"field\":\"Author\",\"transform\":{\"id\":\"1242\"}},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":20},\"x\":{\"field\":\"Rating\"},\"y\":{\"field\":\"Customers_Rated\"}},\"id\":\"1279\",\"type\":\"Scatter\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1268\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"axis_label\":\"RATING\",\"formatter\":{\"id\":\"1284\"},\"ticker\":{\"id\":\"1255\"}},\"id\":\"1254\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1266\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1246\",\"type\":\"DataRange1d\"},{\"attributes\":{\"axis\":{\"id\":\"1258\"},\"dimension\":1,\"ticker\":null},\"id\":\"1261\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1288\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1252\",\"type\":\"LinearScale\"},{\"attributes\":{\"label\":{\"field\":\"Author\"},\"renderers\":[{\"id\":\"1280\"}]},\"id\":\"1291\",\"type\":\"LegendItem\"},{\"attributes\":{\"source\":{\"id\":\"1276\"}},\"id\":\"1281\",\"type\":\"CDSView\"},{\"attributes\":{\"data\":{\"Author\":[],\"Book Name\":[],\"Customers_Rated\":[],\"Price\":{\"__ndarray__\":\"\",\"dtype\":\"int32\",\"order\":\"little\",\"shape\":[0]},\"Rating\":[],\"index\":[]},\"selected\":{\"id\":\"1288\"},\"selection_policy\":{\"id\":\"1287\"}},\"id\":\"1276\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1286\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"text\":\"Top Authors: Rating vs. Customers Rated\"},\"id\":\"1244\",\"type\":\"Title\"}],\"root_ids\":[\"1243\"]},\"title\":\"Bokeh Application\",\"version\":\"2.1.1\"}};\n",
       "  var render_items = [{\"docid\":\"be7f1599-965e-4a1b-ae6f-e422815ed50f\",\"root_ids\":[\"1243\"],\"roots\":{\"1243\":\"ccfb83ad-7287-4abd-973d-025260f2dd73\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1243"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
